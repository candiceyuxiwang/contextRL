---
title: "model_sim"
author: "Candice Wang"
date: "8/2/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## modeling a simulated restless 4-arm bandit task

In bandit_sim.rmd, we simulated 50 subjects' choices on Daw et al., 2006's restless 4-arm bandit task. Like real subjects, each simulated subject was exposed to one of 3 reward schedule instantiations.

We can compare computational models with different learning and choice rules to discern behavioral signatures of directed exploration, random exploration, exploitation, and perserveration.

The first class of models use the classic delta rule (Sutton & Barto, 1998) as the learning rule, with a constant learning rate. the learning rule can be combined with 4 different choice rules (Chakroun et al., 2020).

The first choice rule is a standard softmax, with 1 free parameter beta (inverse temperature) modeling inherent choice randomness.

```{r}
library(rstan)
sim_data_list  <- list(
             totalTrials = nrow(sim_data), 
             nSubjects = max(sim_data$subject), 
             subject = sim_data$subject, 
             trialNum = sim_data$trialnum,
             choices = sim_data$choice, 
             rewards = sim_data$reward
             ) 
# fit to model 1 with delta learning rule and standard softmax choice rule
sim_fit_delta_SM <- stan(
  file = "delta_SM.stan",  # Stan program
  data = sim_data_list,    # named list of data
  chains = 4,             # number of Markov chains
  warmup = 200,          # number of warmup iterations per chain
  iter = 400,            # total number of iterations per chain
  cores = 4
  )

print(sim_fit_delta_SM, pars = c("beta_mu","beta_sigma","eta_mu","eta_sigma","alpha_mu","alpha_sigma"))
stan_hist(sim_fit_delta_SM, pars = c("beta_mu","beta_sigma","alpha_mu","alpha_sigma"))

# LOOCV
library(loo)
loo_delta_SM <- loo(sim_fit_delta_SM)
```

Beta is well below 0, meaning that choices rely on estimated value differences between arms to a small degree. Alpha (learning rate) is high, suggesting that a large proportion of the prediction error is used to update estimated values.

The second choice rule includes an additional exploration bonus term, which scales with the estimated uncertainty of the chosen bandit (directed exploration). In delta rule model, this exploration bonus for a bandit scales linearly with the number of trials since it was last chosen (cf. Chakroun et al., 2020; Speekenbrink & Konstantinidis, 2015). 

```{r}
# compute exploration bonus
exploration_bonus <- matrix(nrow = nrow(sim_data), ncol = 4)
for (t in 1:(nrow(sim_data)-1)){
  if(sim_data$trialnum[t]==1){
    exploration_bonus[t,] <- 1
  }
  for (i in 1:4){
     # for each arm, see check the last time that it was chosen
    if(length(which(sim_data$choice[(1+(sim_data$subject[t]-1)*150):t] %in% i))==0){
      exploration_bonus[t+1,i] <- t - (sim_data$subject[t]-1)*150 # hasn't been chosen before
    }else{
      exploration_bonus[t+1,i] <- t - (max(which(sim_data$choice[(1+(sim_data$subject[t]-1)*150):t] %in% i)) + (sim_data$subject[t]-1)*150)
    }
  }
}

# make new data list with exploration bonus
sim_data_list_1  <- list(
             totalTrials = nrow(sim_data), 
             nSubjects = max(sim_data$subject), 
             subject = sim_data$subject, 
             trialNum = sim_data$trialnum,
             choices = sim_data$choice, 
             rewards = sim_data$reward,
             eb = exploration_bonus
             ) 

# fit
sim_fit_delta_SME <- stan(
  file = "delta_SME.stan",  # Stan program
  data = sim_data_list_1,    # named list of data
  chains = 4,             # number of Markov chains
  warmup = 200,          # number of warmup iterations per chain
  iter = 400,            # total number of iterations per chain
  cores = 4
  )
print(sim_fit_delta_SME, pars = c("beta_mu","beta_sigma","eta_mu","eta_sigma","alpha_mu","alpha_sigma","phi_mu","phi_sigma"))
stan_hist(sim_fit_delta_SME, pars = c("beta_mu","beta_sigma","alpha_mu","alpha_sigma","phi_mu","phi_sigma"))

# LOOCV 
loo_delta_SME <- loo(sim_fit_delta_SME)
loo_compare(loo_delta_SM, loo_delta_SME)
```

The second model with directed exploration bonus term fit the simulated data better.

The third choice rule additionally takes into account perserveration - the arm chosen in the immediate last trial received a perserveration bonus (free parameter persev).

```{r}
sim_fit_delta_SMEP <- stan(
  file = "delta_SMEP.stan",  # Stan program
  data = sim_data_list_1,    # named list of data
  chains = 4,             # number of Markov chains
  warmup = 200,          # number of warmup iterations per chain
  iter = 400,            # total number of iterations per chain
  cores = 4
  )

print(sim_fit_delta_SMEP, pars = c("beta_mu","beta_sigma","eta_mu","eta_sigma","alpha_mu","alpha_sigma","phi_mu","phi_sigma","persev_mu","persev_sigma"))
stan_hist(sim_fit_delta_SMEP, pars = c("beta_mu","beta_sigma","alpha_mu","alpha_sigma","phi_mu","phi_sigma","persev_mu","persev_sigma"))

# LOOCV 
loo_delta_SMEP <- loo(sim_fit_delta_SMEP)
loo_compare(loo_delta_SME, loo_delta_SMEP)
```

The two models with and without perserveration component have similar predictive powers.

Lastly, the fourth choice rule that we will combine with the delta learning rule includes a random exploration bonus, which is discounted by the total uncertainty across all the arms (cf. Chakroun et al., 2020; Gershman, 2018).

```{r}
sim_fit_delta_SMEPR <- stan(
  file = "delta_SMEPR.stan",  # Stan program
  data = sim_data_list_1,    # named list of data
  chains = 4,             # number of Markov chains
  warmup = 200,          # number of warmup iterations per chain
  iter = 400,            # total number of iterations per chain
  cores = 4
  )
print(sim_fit_delta_SMEPR, pars = c("beta_mu","beta_sigma","eta_mu","eta_sigma","alpha_mu","alpha_sigma","phi_mu","phi_sigma","persev_mu","persev_sigma","gamma_mu","gamma_sigma"))

stan_hist(sim_fit_delta_SMEPR, pars = c("beta_mu","beta_sigma","alpha_mu","alpha_sigma","phi_mu","phi_sigma","persev_mu","persev_sigma","gamma_mu","gamma_sigma"))

loo_delta_SMEPR <- loo(sim_fit_delta_SMEPR)
loo_compare(loo_delta_SME, loo_delta_SMEP, loo_delta_SMEPR)
```

Here, the posterior for random exploration bonus hyperparameter is above 0, indicating that there's no strong evidence for random exploration bonus (not surprising given that the simulated data did not have a random exploration bonus). This model does not have significantly higher predictive power than the two previous models.

```{r}
# Bayesian model
sim_fit_Bayes_SMEP <- stan(
  file = "Bayes_SMEP.stan",  # Stan program
  data = sim_data_list,    # named list of data
  chains = 4,             # number of Markov chains
  warmup = 200,          # number of warmup iterations per chain
  iter = 400,            # total number of iterations per chain
  cores = 4
  )

traceplot(sim_fit_Bayes_SMEP, pars = c("beta_mu","beta_sigma","phi_mu","phi_sigma","persev_mu","persev_sigma"))
print(sim_fit_Bayes_SMEP, pars = c("beta_mu","beta_sigma","phi_mu","phi_sigma","persev_mu","persev_sigma"))
stan_hist(sim_fit_Bayes_SMEP, pars = c("beta_mu","beta_sigma","phi_mu","phi_sigma","persev_mu","persev_sigma"))
```

The Bayes SMEP model, which is the groud-truth model for the simulated data that adjusts learning rate with a kalman filter and has perserveration and directed exploration bonuses, was able to recover the parameters reasonably. 

Now, we can try fitting the data again using only the first 50 trials to see if it would work with fewer data points.
```{r}
# first 50 trials only
sim_data_short <- filter(sim_data, trialnum <=50)

sim_data_short_list  <- list(
             totalTrials = nrow(sim_data_short), 
             nSubjects = max(sim_data_short$subject), 
             subject = sim_data_short$subject, 
             trialNum = sim_data_short$trialnum,
             choices = sim_data_short$choice, 
             rewards = sim_data_short$reward
             ) 

sim_short_fit_Bayes_SMEP <- stan(
  file = "Bayes_SMEP.stan",  # Stan program
  data = sim_data_short_list,    # named list of data
  chains = 4,             # number of Markov chains
  warmup = 200,          # number of warmup iterations per chain
  iter = 400,            # total number of iterations per chain
  cores = 4
  )
traceplot(sim_short_fit_Bayes_SMEP, pars = c("beta_mu","beta_sigma","phi_mu","phi_sigma","persev_mu","persev_sigma"))
print(sim_short_fit_Bayes_SMEP, pars = c("beta_mu","beta_sigma","phi_mu","phi_sigma","persev_mu","persev_sigma"))
stan_hist(sim_short_fit_Bayes_SMEP, pars = c("beta_mu","beta_sigma","phi_mu","phi_sigma","persev_mu","persev_sigma"))
```

01/05/2022 
We can simulate two conditions, imperative information seeking and interrogative information seeking, which may lead to different propensities in directed exploration (making choices to resolve uncertainty). We can now fit the two-condition version of the Bayes SMEP model to the simulated data.

```{r}
sim_data_cond_list  <- list(
             totalTrials = nrow(sim_data), 
             nSubjects = max(sim_data$subject), 
             subject = sim_data$subject, 
             trialNum = sim_data$trialnum,
             choices = sim_data$choice, 
             rewards = sim_data$reward,
             condition = sim_cond
             ) 

sim_fit_Bayes_SMEP_cond <- stan(
  file = "Bayes_SMEP_cond.stan",  # Stan program
  data = sim_data_cond_list,    # named list of data
  chains = 4,             # number of Markov chains
  warmup = 100,          # number of warmup iterations per chain
  iter = 200,            # total number of iterations per chain
  cores = 4
  )

traceplot(sim_fit_Bayes_SMEP_cond, pars = c("beta_mu","beta_sigma","phi_mu","phi_sigma","persev_mu","persev_sigma"))

print(sim_fit_Bayes_SMEP_cond, pars = c("beta_mu","beta_sigma","phi_mu","phi_sigma","persev_mu","persev_sigma", "beta_diff","phi_diff","persev_diff"))

# parameter recovery
library(bayesplot)
draws <- as.matrix(sim_fit_Bayes_SMEP_cond)[, 1:9]
true <- c(0.3, 0.3, 0.1, 1.0, 1.5, 0.1, 4, 4, 0.1)
mcmc_recover_intervals(draws, true, batch = 1:ncol(draws))
mcmc_recover_scatter(draws, true)
```

The two-condition Bayes_SMEP model was able to recover the parameters for simulated data reasonably well.

We can also try the two-condition delta_SMEP model, using simulated data where the delta learning rule is the ground-truth data generating mechanism.

```{r}
# from bandit_sim
sim_data_list_delta  <- list(
             totalTrials = nrow(sim_data), 
             nSubjects = max(sim_data$subject), 
             subject = sim_data$subject, 
             trialNum = sim_data$trialnum,
             choices = sim_data$choice, 
             rewards = sim_data$reward,
             eb = as.matrix(sim_data[,6:9]), # em_arm1:4
             condition = sim_cond,
             nSubCond1 = sum(sim_cond==1)
             ) 

sim_fit_delta_SMEP_cond <- stan(
  file = "delta_SMEP_cond.stan",  # Stan program
  data = sim_data_list_delta,    # named list of data
  chains = 4,             # number of Markov chains
  warmup = 200,          # number of warmup iterations per chain
  iter = 400,            # total number of iterations per chain
  cores = 4
  )

print(sim_fit_delta_SMEP_cond, pars = c("eta_mu","eta_sigma","alpha_mu", "alpha_sigma", "beta_mu","phi_mu","persev_mu","alpha_diff","beta_diff","phi_diff","persev_diff"))

traceplot(sim_fit_delta_SMEP_cond, pars = c("eta_mu","eta_sigma","alpha_mu", "alpha_sigma", "beta_mu","beta_sigma", "phi_mu","phi_sigma","persev_mu","persev_sigma"))

stan_hist(sim_fit_delta_SMEP_cond, pars = c("eta_mu","eta_sigma","alpha_mu", "alpha_sigma", "beta_mu","phi_mu","persev_mu","alpha_diff","beta_diff","phi_diff","persev_diff"))

# diagnostics
check_hmc_diagnostics(sim_fit_delta_SMEP_cond)

library(bayesplot)
# pairs plot
pairs(sim_fit_delta_SMEP_cond, pars = c("eta_mu","eta_sigma","alpha_mu", "alpha_sigma", "beta_mu","phi_mu","persev_mu"))
# rank plot
sim_fit_delta_SMEP_cond_posterior <- as.array(sim_fit_delta_SMEP_cond, par=c("eta_mu[1]","eta_mu[2]","eta_sigma", "beta_mu[1]", "beta_mu[2]","beta_sigma", "phi_mu[1]","phi_mu[2]","phi_sigma","persev_mu[1]","persev_mu[2]", "persev_sigma"))
mcmc_rank_hist(sim_fit_delta_SMEP_cond_posterior, par =c("eta_mu[1]","eta_mu[2]","eta_sigma","beta_mu[1]", "beta_mu[2]", "phi_mu[1]","phi_mu[2]"))

stan_par(sim_fit_delta_SMEP_cond, par = "eta_sigma")

np <- nuts_params(sim_fit_delta_SMEP_cond)
mcmc_neff(neff_ratio(sim_fit_delta_SMEP_cond, pars = c("eta_mu","eta_sigma","alpha_mu", "alpha_sigma", "beta_mu","phi_mu","persev_mu","alpha_diff","beta_diff","phi_diff","persev_diff")), size = 2)
```

the model has some sampling problems 

We can try an alternative parameterization of the hyperparameters that specifiies the difference between two groups as eta_mu_diff, beta_mu_diff, and phi_mu_diff.

```{r}
print(sim_fit_delta_SMEP_cond_alt, pars = c("eta_mu","eta_sigma","alpha_mu", "alpha_sigma","beta_mu","beta_sigma","phi_mu","phi_sigma","persev_mu","persev_sigma", "alpha_mu_diff","beta_mu_diff","phi_mu_diff","eta_mu_diff"))
# still having issues with phi_sigma and eta_sigma
```

two condition delta_SM?

```{r}
sim_data_list_delta_SM  <- list(
    totalTrials = nrow(sim_data), 
    nSubjects = max(sim_data$subject), 
    subject = sim_data$subject, 
    trialNum = sim_data$trialnum,
    choices = sim_data$choice, 
    rewards = sim_data$reward,
    condition = sim_cond,
    nSubCond1 = sum(sim_cond==1)
) 

print(sim_fit_delta_SM_cond, pars = c("eta_mu","eta_sigma","alpha_mu", "alpha_sigma","beta_mu","beta_sigma", "alpha_mu_diff","beta_mu_diff","eta_mu_diff"))
```

